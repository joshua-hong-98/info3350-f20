{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**19 October 2020**\n",
    "\n",
    "# Explainability and feature importance\n",
    "\n",
    "## Admin\n",
    "\n",
    "* Problem set 7 (corpus building) due Tuesday night by 11:59pm\n",
    "* Read Piper chapter (on Canvas) for Wednesday\n",
    "    * If writing a response, post to Canvas by Tuesday evening at 9:00pm\n",
    "    * Three total responses due by 11/11\n",
    "* Problem set 8 (mini-project) available by Tusday night, due in one or two weeks (see poll)\n",
    "    * The task will be to explore the corpus built in PS 7, offering a hypothesis, experiments, and reflection on your findings\n",
    "    * Start thinking now about what you'd like to do\n",
    "    * Solo or in a group of no more than 3 students\n",
    "    * Expectations scaled to group size\n",
    "* Poll re: mini-project due date and weight\n",
    "    * If we push it back a week, there will be one fewer problem set (psets 9 and 10 rolled into one)\n",
    "    * I'm leaning strongly toward the extra week/double weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explaining your model\n",
    "\n",
    "### What does it mean to \"explain\" a model?\n",
    "\n",
    "**Can you tell someone else (or yourself!) how it works?**\n",
    "\n",
    "* What are your inputs?\n",
    "* Where do your data come from?\n",
    "* What algorithm did you use?\n",
    "* How did you select your parameters (for preprocessing, algorithm selection, hyperparameters, etc.)\n",
    "* How accurate are your results?\n",
    "* On what kinds of objects does the model perform well or badly?\n",
    "* What features most impact classification accuracy?\n",
    "    * Overall?\n",
    "    * For any given object?\n",
    "\n",
    "### Why is explainability important?\n",
    "\n",
    "In general:\n",
    "\n",
    "* Can you convince someone (or yourself) that your model is trustworthy?\n",
    "* Are there errors or anomalies in your data/processing/code?\n",
    "    * Consider a British/American text classifier that uses frequency of \"colour\" or \"lorry\"\n",
    "    * Or a news article topic classifier that includes source names like \"The Wall Street Journal\" or \"The Sporting News\" in its input\n",
    "        * Not wrong, but fragile, not generalizable\n",
    "* When the classifier makes mistakes, why did it fail?\n",
    "* Is your classifer biased?\n",
    "    * Are the features driving your model ones that you trust? Or that you *should* use?\n",
    "    * Consider ZIP code or prior arrest for predicting recidivism\n",
    "    \n",
    "In some cases:\n",
    "\n",
    "* Maybe you care about the features\n",
    "    * Consider medical treatment. Give five drugs, which ones drive recovery?\n",
    "* Maybe the features help you understand the (high-level) phenomenon you're modeling\n",
    "    * For example, authorship attribution via stopword frquency\n",
    "\n",
    "### Must you care about explaining your model?\n",
    "\n",
    "* Probably, but sometimes more than others\n",
    "* Things that decrease the need for explainability:\n",
    "    * You only care about accuracy/performance\n",
    "    * You will only ever work with one dataset\n",
    "        * And you have high confidence in its quality\n",
    "    * The stakes of your classification are low\n",
    "        * No one is harmed if/when you're wrong\n",
    "    * The costs of modeling are low (so that you don't need to justify your existence to a funder)\n",
    "* This is all to say: **If your problem is important, explainability is important**\n",
    "    \n",
    "## Types of explanation\n",
    "\n",
    "### Intrinsic and model-specific\n",
    "\n",
    "* Does your model produce individual feature weights or decision criteria?\n",
    "    * Linear models, trees\n",
    "* Do you know in advance which model(s) you'll use?\n",
    "    * Recall we noted that decision trees are popular because they are so easily interpretable, even when they rarely offer best performance\n",
    "\n",
    "### *Post hoc* and model-agnostic\n",
    "\n",
    "* Is your model a \"black box\"?\n",
    "    * Ensembles, neural networks\n",
    "* Do you want to be able to use/interpret/explain an arbitrary classifier?\n",
    "\n",
    "### Local or global?\n",
    "\n",
    "* Do you need to identify the most important features overall? (global)\n",
    "* Do you need to be able to identify the most important features for an individual classification? (local)\n",
    "\n",
    "## Some approaches\n",
    "\n",
    "### Linear methods\n",
    "\n",
    "* Examples: Logistic regression, Lasso, Ridge\n",
    "* Intrinsic, global\n",
    "* Many `sklearn` classifiers have a `.coef_` attribute of the trained classifer object. \n",
    "* This provides the coefficients of each feature in the input matrix.\n",
    "\n",
    "### Trees\n",
    "\n",
    "* Example: Decison tree, Random forest (by extension)\n",
    "* Intrinsic, global\n",
    "* Has an attribute `feature_importances_`\n",
    "* Reflects the degree to which each feature separates the classes\n",
    "    * \"How much does selecting on a feature reduce the impurity of the classes?\"\n",
    "\n",
    "### Permutation\n",
    "\n",
    "* Can be used with black box models\n",
    "* Is *post hoc*\n",
    "* Note that this is one version of what we mentioned last week when we mentioned *post hoc* feature selection\n",
    "* In brief:\n",
    "    * Measure model performance (accuracy, f1, etc.)\n",
    "    * Shuffle (permute) the values of one feature for all the objects \n",
    "        * This renders the feature non-informative\n",
    "    * Measure model performance again\n",
    "        * It will drop, unless the feature was non-informative to begin with (in which case, it'll stay about the same)\n",
    "    * Repeat for all features\n",
    "    * The features that, when shuffled, produce the largest drop in classification performance are the most important ones\n",
    "\n",
    "### Partial dependence\n",
    "\n",
    "* Often most useful for regression, but can be adapted to classification\n",
    "* Asks: by how much does the response variable change when I make a small change to the input variable across a range of possible input values?\n",
    "    * For classification, need to measure something like the change in class probability\n",
    "    * Note that some `sklearn` classifiers (including `RandomForestClassifier` and `LogisticRegression`) include a `.predict_proba()` method to predict probabilities\n",
    "        * Output of `predict_proba` is a vector of class probabilities rather than a single (most likely) class label for each object\n",
    "* Can help to identify non-linear relationships between input and reponse\n",
    "    * For example, bike rentals are a function of temperature (among other things)\n",
    "    * Rentals go up with increasing temperature ...\n",
    "    * ... until it becomes too hot (at which point they decrease with temperature)\n",
    "\n",
    "## Packages \n",
    "\n",
    "* Scikit-learn\n",
    "    * [sklearn.inspection.permutation_importance](https://scikit-learn.org/stable/modules/permutation_importance.html)\n",
    "    * [sklearn.inspection.partial_dependence](https://scikit-learn.org/stable/auto_examples/inspection/plot_partial_dependence.html#sphx-glr-auto-examples-inspection-plot-partial-dependence-py)\n",
    "* [skater](https://oracle.github.io/Skater/overview.html)\n",
    "* [lime](https://github.com/marcotcr/lime)\n",
    "* [ELI5](https://eli5.readthedocs.io/en/latest/overview.html)\n",
    "* [SHAP](https://shap.readthedocs.io/en/latest/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
