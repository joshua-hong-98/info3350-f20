{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**21 September 2020**\n",
    "\n",
    "# Vectorization, distance metrics, and regression\n",
    "\n",
    "## Admin\n",
    "\n",
    "* Response one due by tomorrow at 9:00pm if not already done.\n",
    "* PS3 due by tomorrow at 11:59.\n",
    "* Read Moretti for Wednesday\n",
    "* LeAnn's office hours this afternoon (2-3pm, see Canvas for link)\n",
    "* Questions?\n",
    "\n",
    "## Definitions\n",
    "\n",
    "* What is a **vector**?\n",
    "  * An ordered collection of numbers that locate a point in space relative to a shared reference point (called the *origin*).\n",
    "  * We can also think of vectors as representing the quantified *features* of an object.\n",
    "  * Vectors are usually written as *row matrices*, or just as lists: $vec = [1.0, 0.5, 3.0, 1.2]$\n",
    "  * Vectors have as many *dimensions* as there are features of the object to represent.\n",
    "    * The number of features to represent is a choice of the experiment. There is no correct choice, though some choices are better than others for a given purpose.\n",
    "* What is **vectorization**?\n",
    "  * The process of transforming an object into its vector representation, typically by measuring some of the object's properties.\n",
    "  \n",
    "## Why would we want to do this?\n",
    "\n",
    "* Measuring the properties of objects lets us compare those objects to one another.\n",
    "  * Example: We counted words by type to compare gender and sentiment in novels.\n",
    "* Establishing a vector representation allows us to define a **distance metric** between objects that aren't straightforwardly spatial.\n",
    "  * \"Distance\" is a metaphor. Ditto \"similarity.\"\n",
    "  * Nothing is, in itself, like or unlike anything else. \n",
    "    * We sometimes seek to assert that objects are similar by erasing aspects of their particularity.\n",
    "  * Measuring similarity and difference are (always and only) interpretive interventions.\n",
    "  \n",
    "## A spatial example\n",
    "\n",
    "Consider this map of central campus:\n",
    "\n",
    "<img src=\"./images/clock_tower.jpg\" width=\"150\"><br />\n",
    "<img src=\"./images/cornell_map.png\" width=\"500\"><img src=\"./images/gates.jpg\" width=\"250\">\n",
    "\n",
    "**How far apart are Gates Hall (purple star) and the clock tower (orange star)?**\n",
    "\n",
    "What do we need to know or define in order to answer this question?\n",
    "\n",
    "* Where is each building in physical space.\n",
    "  * Latitude/longitude; meters north/south and east/west of the book store; etc.\n",
    "* How do we want to measure the distance between them (walking, driving, flying, tunneling, ...). Minutes or miles?\n",
    "\n",
    "Normal, boring answer: about 0.4 miles on foot via Campus Rd and Ho Plaza, or a bit less if you cut some corners, or less than 0.3 miles if you can fly.\n",
    "\n",
    "More interesting version: How far apart are these buildings conceptually? Architecturally? Historically? \n",
    "\n",
    "* What are the features and metrics you would use to answer this question?\n",
    "* This is a lot more like the problem of comparing texts.\n",
    "\n",
    "## A textual example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 'My cat likes water.')\n",
      "(1, 'The dog eats food.')\n",
      "(2, 'The dog and the cat play together.')\n",
      "(3, 'A dog and a cat meet another dog and cat.')\n",
      "(4, 'The end.')\n"
     ]
    }
   ],
   "source": [
    "text = '''\\\n",
    "My cat likes water.\n",
    "The dog eats food.\n",
    "The dog and the cat play together.\n",
    "A dog and a cat meet another dog and cat.\n",
    "The end.'''\n",
    "\n",
    "# Print with sentence numbers\n",
    "for line in enumerate(text.split('\\n')):\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us stipulate that we want to compare these five sentences according to their \"*dogness*\" and \"*catness*.\" We care about those two aspects alone, nothing else.\n",
    "\n",
    "Let's develop some intuitions here:\n",
    "\n",
    "* Sentences 0 and 1 are as far apart as can be: 0 is about cats, 1 is about dogs.\n",
    "* Sentence 2 lies between 0 and 1. It contains a mix of dogness and catness.\n",
    "* Sentence 3 is kind of like sentence 2, but it has twice as much of both dogness and catness.\n",
    "  * How different are sentences 2 and 3? (There's no objectively correct answer.)\n",
    "* Sentence 4 is a zero point. It has no dogness or catness.\n",
    "\n",
    "### Count relevant words\n",
    "\n",
    "||**cat**|**dog**|\n",
    "|---|---|---|\n",
    "|**sent**| | |\n",
    "|0|1|0|\n",
    "|1|0|1|\n",
    "|2|1|1|\n",
    "|3|2|2|\n",
    "|4|0|0|\n",
    "\n",
    "The **vector representation** of sentence 0 is [1, 0]. The vector representation of sentence 3 is [2, 2]. And so on ...\n",
    "### Visualize (scatter plot)\n",
    "\n",
    "Sketch this by hand ...\n",
    "\n",
    "### Distance measures\n",
    "\n",
    "How far apart are sentences 0 and 1 (and all the rest)?\n",
    "\n",
    "#### Manhattan distance\n",
    "\n",
    "* Also called \"city block\" distance. \n",
    "* Not much used, but easy to understand. \n",
    "* Sum of the absolute difference in each dimension.\n",
    "\n",
    "For **sentences 0 and 1**, the Manhattan distance = |1| + |-1| = 2.\n",
    "\n",
    "#### Euclidean distance\n",
    "\n",
    "* Straight-line or \"as the crow flies\" distance. \n",
    "* Widely used in data science, but not always the best choice for textual data.\n",
    "\n",
    "Recall the Pythagorean theorem for the hypotenuse of a triangle: $a^2 = b^2 + c^2$ or $a = \\sqrt{b^2 +c^2}$.\n",
    "\n",
    "For **sentences 0 and 1**, the Euclidean distance = $\\sqrt{1^2 + 1^2} = \\sqrt{2} = 1.414$.\n",
    "\n",
    "OK, but what about the Euclidean distance between **sentence 0 and sentence 3**? Well, that distance = $\\sqrt{1^2 + 2^2} = \\sqrt{5} = 2.24$.\n",
    "\n",
    "And between **sentences 2 and 3** (both balanced 50:50 between dogs and cats)? That's 1.4 again, the same as the distance between sentences 0 and 1 (which, recall, are totally divergent in dog/cat content).\n",
    "\n",
    "An obvious improvement in this case would be to **normalize word counts by document length**.\n",
    "\n",
    "#### Cosine distance\n",
    "\n",
    "Maybe instead of distance, we could measure the difference in **direction** from the origin between points.\n",
    "\n",
    "* **Sentences 0 and 1** are 90 degrees apart.\n",
    "* **Sentences 2 and 3** are 0 degrees apart.\n",
    "* **Sentences 0 and 1** are each 45 degrees away from **sentences 2 and 3**.\n",
    "\n",
    "Now, recall the values of the **cosine** of an angle between 0 and 90 degrees. (Sketch by hand)\n",
    "\n",
    "So, the cosines of the angles between sentences are:\n",
    "\n",
    "sentences|angle|cosine\n",
    "---|---|---\n",
    "0 and 1|90|0\n",
    "2 and 3|0|1\n",
    "0 and 2|45|0.707\n",
    "0 and 3|45|0.707\n",
    "1 and 2|45|0.707\n",
    "\n",
    "We could then transform these cosine **similarities** into **distances** by subtracting them from 1, so that the most *dissimilar* sentences (like 0 and 1) have the greatest distance between them.\n",
    "\n",
    "The big advantage here is that we don't need to worry about getting length normalization right. Cosine distance is often a good choice for text similarity tasks.\n",
    "\n",
    "#### Higher dimensions\n",
    "\n",
    "All of these metrics can be calculated in arbitrarily many dimensions. Which is good, because textual data is often very high-dimensional. Imagine counting the occurrences of each word type in a large corpus of novels or historical documents. Can easily be tens of thousands of dimensions.\n",
    "\n",
    "## In the real world\n",
    "\n",
    "* There's nothing wrong with any of these distance metrics, exactly, but they're not state of the art.\n",
    "* If you've done some recent NLP work, you'll know that, at the very least, you'd want to use word embeddings in place of raw tokens.\n",
    "  * This allows you to capture the similarity of meaning between, e.g., \"cat\" and \"kitten.\"\n",
    "* If you were especially ambitious, you'd be looking at something like BERT or ELMo or GPT-2/3, etc.\n",
    "\n",
    "Here, though, we're trying to grasp the *idea* behind document similarity, on which all of these methods depend: transform text into a numeric representation of its meanings, then quantify the difference or similarity between those numeric representations.\n",
    "\n",
    "## In the problem set world\n",
    "\n",
    "We'll dig into how, as a practical matter, we can vectorize texts and calclulate distance metrics in this week's problem set.\n",
    "\n",
    "## Regression\n",
    "\n",
    "We are often interested in the relationships between measured properties of texts, or between a textual property and some other variable (year of publication, number of sales, and so on).\n",
    "\n",
    "Maybe the most basic way to measure the relationship between two variables is to use **linear regression**. The idea is to calculate a straight line through your data such that the average distance between the observed data points and the line is as small as possible. \n",
    "\n",
    "(Sketch what this looks like)\n",
    "\n",
    "You can then calculate the **coefficient of determination**, written $r^2$ (\"r squared\"), which measures the fraction of the variation in the dependent (y) variable that is predictable from the independent (x) variable.\n",
    "\n",
    "$r^2$ = 1 - (sum of squared residuals)/(sum of squared values)\n",
    "\n",
    "An $r^2$ value of 1 indicates perfect correlation between the variables; zero means no correlation. \n",
    "\n",
    "* There's a *lot* more to this. We'll spend some time on it later in the semester.\n",
    "* For now, focus on the fact that regression is a way to calculate a line of best fit through a data set.\n",
    "* Notice that we could also try to find something like a \"line of *worst* fit,\" which we could think of as the dividing line between two regions of feature space. This would be something like the line on which we are least likely to encounter any actual data points. \n",
    "  * Think about what use-value such a dividing line might have ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
