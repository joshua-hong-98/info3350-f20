{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**11 November 2020**\n",
    "\n",
    "# Discussion: Barron et al.\n",
    "\n",
    "## Admin\n",
    "\n",
    "* PS 10 due **Friday** night by 11:59pm\n",
    "* No sections on Friday\n",
    "    * No new problem set this week\n",
    "    * I'll hold office hours from 10:20-12:05, but not 3-4pm\n",
    "    * No work due over break\n",
    "* Grade weight clarification about the mini-project:\n",
    "    * Syllabus says problem sets are worth 50%, mini-project 15% of total grade\n",
    "    * But our in-class discussion suggested otherwise\n",
    "    * Mini-project, as PS 8, counts the same as any other problem set\n",
    "    * All problem sets together, including PS 8, will count for 65% of your course grade\n",
    "    \n",
    "## Finish topic models lecture\n",
    "\n",
    "* Resume code walk-through ...\n",
    "\n",
    "## Discussion: Barron et al.\n",
    "\n",
    "For reference, note the corpus and methods of the study:\n",
    "\n",
    "* About 40,000 speeches delivered in the French National Assembly between 1789 and 1791 (so, early in the revolution, which began in May, 1789). About 4.5M words total (avergae speech thus c. 100 words).\n",
    "    * Not a huge corpus. About the same as 40-50 novels.\n",
    "    * Consistent setting: speakers in a version of dialogue, one speech at a time, following another, delivered to the same audience.\n",
    "* LDA to quantify the content of each speech (no chunking, becasue short documents)\n",
    "* Kullback-Liebler Divergence to measure the difference between speeches at varying \"distances\" (everything from one speech to the next, up to speeches separated by 1,000 others)\n",
    "    * KLD is simple and powerful. Here, it's calculated as the weighted sum over all topics of the (base-2) log of the ratio between topic fractions in the two speeches being compared.\n",
    "    * As the name suggests, greater differences in the distribution over topics between two texts produces a larger KLD value.\n",
    "\n",
    "A **ton** of interesting responses to this one. So, we'll go to breakout rooms without assigned questions. If you wrote a response for today -- or even if you didn't! -- discuss your ideas with the others in your room. Be prepared to present your insights, questions, and suggestions to the class when we reconvene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
