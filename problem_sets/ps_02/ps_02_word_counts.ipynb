{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem set 1: Counting words\n",
    "\n",
    "## Description\n",
    "\n",
    "The goal of this problem set is to create the world's least visually-sophisticated word count graphic.\n",
    "\n",
    "Along the way, you'll experiment with stopword removal, case folding, and other processing steps.\n",
    "\n",
    "## Count words, naïvely\n",
    "\n",
    "We'll work with *Moby-Dick*, as we did in class. \n",
    "\n",
    "**Read the text of *Moby-Dick* from a file (it's on the class GitHub site, in the `data/texts` directory), tokenize it with NLTK's `word_tokenize` function, and count the resulting tokens in a `Counter` object.**\n",
    "\n",
    "You can refer to the lecture notebook from Monday, September 7, to borrow code to do all of this. But you must get that code working in the cell below. This cell should produce a `Counter` object that holds the token counts from the novel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use standard Python file commands to open Moby-Dick,\n",
    "#  then count the words in that file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Print the total number of words (hint: use `Counter`'s `.values()` method, along with the `sum` function) in your text, as well as the 20 most frequently occurring terms and their counts.**\n",
    "\n",
    "We'll do this a lot, so wrap it up as a function that takes as input a `Counter` object and an optional number of top terms to print:\n",
    "\n",
    "```\n",
    "def word_stats(data, n=20):\n",
    "```\n",
    "\n",
    "The output of your fuction should look like this:\n",
    "\n",
    "```\n",
    "Total words in the text: 255380\n",
    "\n",
    "Top 20 words by frequency:\n",
    ",      19204\n",
    "the    13715\n",
    ".      7432\n",
    "\n",
    "[and so on ...]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your word_stats function here\n",
    "def word_stats(data, n=20):\n",
    "    '''\n",
    "    Print total wordcount and n top terms.\n",
    "    Takes a Counter object and a number of terms to print.\n",
    "    Returns None.\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call word_stats on your data\n",
    "word_stats(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case folding and stopwords\n",
    "\n",
    "As you can see, the top words that we counted aren't super informative. That said, list two things that you **can** say about the text with reasonable confidence on the basis of our results above:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Two things you *can* tell about *Moby-Dick* from the naïve word counts:**\n",
    "\n",
    "1. Thing one\n",
    "1. Thing two"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want our word list to be informative, we need to find a way to ignore high-frequency, low-information words. We can do this either by not counting them in the first place, or by excluding them from our reporting after we've collected them. Both methods have advantages and drawbacks. The one you pursue is up to you.\n",
    "\n",
    "**Modify the original code to ignore token case (e.g., 'The' and 'the' are both counted as occurrences of the same token; note the `.lower()` method for strings) and to remove the English-language stopwords defined by NLTK (`from nltk.corpus import stopwords`). Then display the total token count and top-20 tokens.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count tokens with case folding and NLTK English stopwords removed\n",
    "\n",
    "... your code here ...\n",
    "\n",
    "word_stats(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is this better? Maybe! **Note one advantage of this stopword-removed count, as well as one disadvantage:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Advantage:**\n",
    "\n",
    "* Advantage details\n",
    "\n",
    "**Disadvantage:**\n",
    "\n",
    "* Disadvantage details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if we can further improve/refine our approach to continue narrowing our word list. Our goal is to produce a list that contains *only* interesting words and ranks them by frequency.\n",
    "\n",
    "**List at least two ideas for modifying the stopword list to better approach our goal:**\n",
    "\n",
    "1. Idea one\n",
    "1. Idea two"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Implement one or more of your ideas to improve the stopword list, then display the output of your new version using `word_stats()`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Better stopwords in action!\n",
    "\n",
    "... your code here ...\n",
    "\n",
    "word_stats(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refine your stoplist until you're satisfied with it. Make sure your code above displays the final output of your `word_stats` function. Then move on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization \n",
    "\n",
    "Now, make the world's least visually-impressive word count graphic. Your task is to produce a visual representation of your top 10 words that shows the relative frquency of those terms.\n",
    "\n",
    "The simplest acceptable version of this visualization is a bar chart. **Complete the starter code below to produce a bar chart of the top ten words in the text.**\n",
    "\n",
    "Your output might look like this:\n",
    "\n",
    "![bar chart](ps_02_bar_chart.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a bar chart of the top 10 words\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get labels and counts\n",
    "labels = ...\n",
    "counts = ...\n",
    "\n",
    "# Create the figure\n",
    "fig, ax = plt.subplots()\n",
    "ax.barh(...)\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: word clouds\n",
    "\n",
    "**This is optional.** Make a word cloud. You can do this the ugly way in pure `matplotlib` or the easy-and-pretty way by using the [`wordcloud`](https://github.com/amueller/word_cloud) library:\n",
    "\n",
    "```\n",
    "conda install -c conda-forge wordcloud\n",
    "```\n",
    "If you use `wordcloud`, you'll be interested in the [`.generate_from_frequencies()` method](http://amueller.github.io/word_cloud/auto_examples/frequency.html).\n",
    "\n",
    "Here are examples of the ugly and the pretty outputs. Your specific results might vary.\n",
    "\n",
    "![ugly](ps_02_ugly_cloud.png)\n",
    "![pretty](ps_02_pretty_cloud.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The ugly way (matplotlib)\n",
    "# Hint: you'll want to use the .text() plotting method\n",
    "# Strictly optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The pretty way\n",
    "# Strictly optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
